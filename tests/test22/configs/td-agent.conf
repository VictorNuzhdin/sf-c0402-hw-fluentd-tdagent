####
## Source descriptions
##

##..Source Section :: Input Plugin
#
# HTTP input
# POST http://localhost:8888/<tag>?json=<json>
# POST http://localhost:8888/td.myapp.login?json={"user"%3A"me"}
<source>
  @type http
  @id input_http
  port 8888
</source>

## live debugging agent
<source>
  @type debug_agent
  @id input_debug_agent
  bind 127.0.0.1
  port 24230
</source>


####
## Filter descriptions
##

## CUSTOM_FILTER #2.2
<filter hosts.test22>
  @type record_transformer
  <record>
    receiver "#{Socket.gethostname}"
  </record>
</filter>


####
## Output descriptions
##

## match tag=debug.** and dump to console
<match debug.**>
  @type stdout
  @id output_stdout
</match>

## CUSTOM_OUTPUT #2.2
## match "tag=hosts.test22" and dump to "/opt/fluent/logs/buffer.<hash>.log"
#                                                        /hosts.test22.20231101044900.json
#
##..Match Section :: Output Plugin
<match hosts.test22>
  @type file
  path /opt/fluent/logs/${tag[0]}/${tag}
  #symlink_path /opt/fluent/logs/current-${tag}    ## BUG (link to unavailable file): current-hosts.test22 -> /opt/fluent/logs/buffer.b6090ac8c99c881607e381e7de51288ac.log
  append true
  add_path_suffix true
  path_suffix ".json"
  #flush_interval 30s    ## this flush_interval is ignored because <buffer> section exist
  #
  ##..Format Section :: Formatter Plugin
  ##  https://docs.fluentd.org/configuration/format-section
  <format>
    @type json
  </format>
  #
  ##..Inject Section
  ##  https://docs.fluentd.org/configuration/inject-section
  <inject>
    tag_key injected_tag
    time_key injected_time
    time_type string
    time_format %Y-%m-%dT%H:%M:%S%z
  </inject>
  #
  ##..Buffer Section
  ##  https://docs.fluentd.org/configuration/buffer-section
  <buffer tag,time>
    @type file
    path /opt/fluent/logs
    timekey 30s
    timekey_wait 0s
    #
    ##..the max number of events that each chunks can store in it
    chunk_limit_records 100
    #
    ##..the max size of each chunks: events will be written into chunks until the size of chunks become this size
    ## Default: 8MB (memory) / 256MB (file) 
    chunk_limit_size 32MB/32MB
    #
    ##..the size limitation of this buffer plugin instance. Once the total size of stored buffer reached this threshold,
    ##  all append operations will fail with error (and data will be lost)
    ##  Default: 512MB (memory) / 64GB (file)
    total_limit_size 64MB/64MB
    #
    queue_limit_length 128
    #
  </buffer>
</match>

